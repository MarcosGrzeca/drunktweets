To build Ensemble # 1, we trained SVMP-SE, DL-WEDS-SE, and XGB-WEDS-SE classifiers individually using the same data set, reserving 80% of the data for training and 20% for tests. We stored the positive class probability for each tweet and classifier. Next, we apply the average over the positive class probabilities for each tweet, as Figure 10, and classify an tweet as `Drunk Tweet' if the average probability is higher than 50 %. This method to combine multiples different classifiers is called stacking. We executed this process five (5) times, recording the average of F1-measure, precision, and recall metrics.


https://blog.nikolaposa.in.rs/2017/01/16/on-structuring-php-projects/


, the improvement of precision was at the exposure of recall to drunk texting situations.

Testar LSTM
Testar LSTM + CNN
Testar LSTM + PCA BoW + PCA semantic features
ConceptNet
Retrofitting

Poderia usar para pegar termos relacionados e zole retrofitting
https://github.com/mfaruqui/retrofitting


SQLS
word 

rede atual + Rede auxiliar com enriquecimento + 

beer abeverage an_alcolic


Posso pegar as métricas do ensemble, concatenar nas word embeddigns e criar uma nova rede neural.
Refazer arquitetura da rede neural, para verificar se está correta!

Também pode ser word vector + três predições

Criar datasets: CSV, contendo.: Para fazer isso, tem que refazer todos os experimentos salvando todas as predições, inclusive do dataset. Somente se eu chamasse como Zero-R.

Tweet: SVM (predict), (DL), and XGBoost.

Usamos bagging: utilizar as predições dos primeiros classificadores para criar um dataset, que passar por um novo classificador.



model <- keras_model_sequential() %>%
			layer_conv_1d(filters = 32, kernel_size = 5, activation = "relu", input_shape = list(NULL, dim(data)[[-1]])) %>%
			layer_max_pooling_1d(pool_size = 3) %>%
			layer_conv_1d(filters = 32, kernel_size = 5, activation = "relu") %>%
			layer_gru(units = 32, dropout = 0.1, recurrent_dropout = 0.5) %>%
			layer_dense(units = 1)

summary(model)
model %>% compile(
	optimizer = optimizer_rmsprop(),
	loss = "mae"
	)