library(caret)
for (year in 1:10) {
dados <- getDadosBaselineByQ("q3")
#dados$textEmbedding <- removePunctuation(dados$textEmbedding)
maxlen <- 38
max_words <- 3080
tokenizer <-  text_tokenizer(num_words = max_words) %>%
fit_text_tokenizer(dados$textEmbedding)
sequences <- texts_to_sequences(tokenizer, dados$textEmbedding)
word_index = tokenizer$word_index
vocab_size <- length(word_index)
vocab_size <- vocab_size + 1
vocab_size
cat("Found", length(word_index), "unique tokens.\n")
data <- pad_sequences(sequences, maxlen = maxlen)
trainIndex <- createDataPartition(dados$resposta, p=0.90, list=FALSE)
dados_train <- dados[ trainIndex,]
dados_test <- dados[-trainIndex,]
dados_train_sequence <- data[ trainIndex,]
dados_test_sequence <- data[-trainIndex,]
max_words <- vocab_size
word_index <- tokenizer$word_index
callbacks_list <- list(
callback_early_stopping(
monitor = "val_loss",
patience = 1
),
callback_model_checkpoint(
filepath = paste0("adhoc/exportembedding/adicionais/test_models.h5"),
monitor = "val_loss",
save_best_only = TRUE
)
)
# Data Preparation --------------------------------------------------------
# Parameters --------------------------------------------------------------
embedding_dims <- 100
filters <- 132
main_input <- layer_input(shape = c(maxlen), dtype = "int32")
main_output <- main_input %>%
layer_embedding(vocab_size, embedding_dims, input_length = maxlen, name = "embedding") %>%
bidirectional(
layer_lstm(units = 128, return_sequences = TRUE)
) %>%
bidirectional(
layer_lstm(units = 64, return_sequences = TRUE, recurrent_dropout = 0.2)
) %>%
bidirectional(
layer_lstm(units = 32)
) %>%
layer_dense(units = 1, activation = 'sigmoid')
model <- keras_model(
inputs = c(main_input),
outputs = main_output
)
model %>% compile(
loss = "binary_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
library(keras)
# Training ----------------------------------------------------------------
history <- model %>%
fit(
x = list(dados_train_sequence),
y = array(dados_train$resposta),
batch_size = 32,
epochs = 5,
#callbacks = callbacks_list,
validation_split = 0.1
)
predictions <- model %>% predict(list(dados_test_sequence))
predictions2 <- round(predictions, 0)
matriz <- confusionMatrix(data = as.factor(predictions2), as.factor(dados_test$resposta), positive="1")
resultados <- addRowAdpater(resultados, "DESC", matriz)
View(resultados)
}
View(resultados)
resultados
library(tools)
library(tm)
source(file_path_as_absolute("ipm/experimenters.R"))
source(file_path_as_absolute("utils/getDados.R"))
source(file_path_as_absolute("baseline/dados.R"))
source(file_path_as_absolute("utils/tokenizer.R"))
resultados <- data.frame(matrix(ncol = 4, nrow = 0))
names(resultados) <- c("Baseline", "F1", "Precisão", "Revocação")
set.seed(18)
library(caret)
for (year in 1:2) {
dados <- getDadosBaselineByQ("q3")
#dados$textEmbedding <- removePunctuation(dados$textEmbedding)
maxlen <- 38
max_words <- 3080
tokenizer <-  text_tokenizer(num_words = max_words) %>%
fit_text_tokenizer(dados$textEmbedding)
sequences <- texts_to_sequences(tokenizer, dados$textEmbedding)
word_index = tokenizer$word_index
vocab_size <- length(word_index)
vocab_size <- vocab_size + 1
vocab_size
cat("Found", length(word_index), "unique tokens.\n")
data <- pad_sequences(sequences, maxlen = maxlen)
trainIndex <- createDataPartition(dados$resposta, p=0.90, list=FALSE)
dados_train <- dados[ trainIndex,]
dados_test <- dados[-trainIndex,]
dados_train_sequence <- data[ trainIndex,]
dados_test_sequence <- data[-trainIndex,]
max_words <- vocab_size
word_index <- tokenizer$word_index
callbacks_list <- list(
callback_early_stopping(
monitor = "val_loss",
patience = 1
),
callback_model_checkpoint(
filepath = paste0("adhoc/exportembedding/adicionais/test_models.h5"),
monitor = "val_loss",
save_best_only = TRUE
)
)
# Data Preparation --------------------------------------------------------
# Parameters --------------------------------------------------------------
embedding_dims <- 100
filters <- 132
main_input <- layer_input(shape = c(maxlen), dtype = "int32")
main_output <- main_input %>%
layer_embedding(vocab_size, embedding_dims, input_length = maxlen, name = "embedding") %>%
bidirectional(
layer_lstm(units = 128, return_sequences = TRUE)
) %>%
bidirectional(
layer_lstm(units = 64, return_sequences = TRUE, recurrent_dropout = 0.2)
) %>%
bidirectional(
layer_lstm(units = 32)
) %>%
layer_dense(units = 1, activation = 'sigmoid')
model <- keras_model(
inputs = c(main_input),
outputs = main_output
)
model %>% compile(
loss = "binary_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
library(keras)
# Training ----------------------------------------------------------------
history <- model %>%
fit(
x = list(dados_train_sequence),
y = array(dados_train$resposta),
batch_size = 32,
epochs = 5,
#callbacks = callbacks_list,
validation_split = 0.1
)
predictions <- model %>% predict(list(dados_test_sequence))
predictions2 <- round(predictions, 0)
matriz <- confusionMatrix(data = as.factor(predictions2), as.factor(dados_test$resposta), positive="1")
resultados <- addRowAdpater(resultados, "DESC", matriz)
View(resultados)
}
View(resultados)
resultados
library(tools)
library(tm)
source(file_path_as_absolute("ipm/experimenters.R"))
source(file_path_as_absolute("utils/getDados.R"))
source(file_path_as_absolute("baseline/dados.R"))
source(file_path_as_absolute("utils/tokenizer.R"))
resultados <- data.frame(matrix(ncol = 4, nrow = 0))
names(resultados) <- c("Baseline", "F1", "Precisão", "Revocação")
set.seed(27)
library(caret)
for (year in 1:10) {
dados <- getDadosChat()
maxlen <- 38
max_words <- 18391
tokenizer <-  text_tokenizer(num_words = max_words) %>%
fit_text_tokenizer(dados$textEmbedding)
sequences <- texts_to_sequences(tokenizer, dados$textEmbedding)
word_index = tokenizer$word_index
vocab_size <- length(word_index)
vocab_size <- vocab_size + 1
vocab_size
cat("Found", length(word_index), "unique tokens.\n")
data <- pad_sequences(sequences, maxlen = maxlen)
trainIndex <- createDataPartition(dados$resposta, p=0.90, list=FALSE)
dados_train <- dados[ trainIndex,]
dados_test <- dados[-trainIndex,]
dados_train_sequence <- data[ trainIndex,]
dados_test_sequence <- data[-trainIndex,]
max_words <- vocab_size
word_index <- tokenizer$word_index
callbacks_list <- list(
callback_early_stopping(
monitor = "val_loss",
patience = 1
),
callback_model_checkpoint(
filepath = paste0("adhoc/exportembedding/adicionais/test_models.h5"),
monitor = "val_loss",
save_best_only = TRUE
)
)
# Data Preparation --------------------------------------------------------
# Parameters --------------------------------------------------------------
embedding_dims <- 100
filters <- 132
main_input <- layer_input(shape = c(maxlen), dtype = "int32")
main_output <- main_input %>%
layer_embedding(vocab_size, embedding_dims, input_length = maxlen, name = "embedding") %>%
bidirectional(
layer_lstm(units = 128, return_sequences = TRUE)
) %>%
bidirectional(
layer_lstm(units = 64, return_sequences = TRUE, recurrent_dropout = 0.2)
) %>%
bidirectional(
layer_lstm(units = 32)
) %>%
layer_dense(units = 1, activation = 'sigmoid')
model <- keras_model(
inputs = c(main_input),
outputs = main_output
)
model %>% compile(
loss = "binary_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
library(keras)
# Training ----------------------------------------------------------------
history <- model %>%
fit(
x = list(dados_train_sequence),
y = array(dados_train$resposta),
batch_size = 32,
epochs = 5,
#callbacks = callbacks_list,
validation_split = 0.1
)
predictions <- model %>% predict(list(dados_test_sequence))
predictions2 <- round(predictions, 0)
matriz <- confusionMatrix(data = as.factor(predictions2), as.factor(dados_test$resposta), positive="1")
resultados <- addRowAdpater(resultados, "DESC", matriz)
View(resultados)
}
View(resultados)
resultados
library(tools)
library(tm)
source(file_path_as_absolute("ipm/experimenters.R"))
source(file_path_as_absolute("utils/getDados.R"))
source(file_path_as_absolute("baseline/dados.R"))
source(file_path_as_absolute("utils/tokenizer.R"))
resultados <- data.frame(matrix(ncol = 4, nrow = 0))
names(resultados) <- c("Baseline", "F1", "Precisão", "Revocação")
set.seed(27)
library(caret)
for (year in 1:10) {
source(file_path_as_absolute("utils/getDadosAmazon.R"))
dados <- getDadosAmazon()
maxlen <- 38
max_words <- 9322
tokenizer <-  text_tokenizer(num_words = max_words) %>%
fit_text_tokenizer(dados$textEmbedding)
sequences <- texts_to_sequences(tokenizer, dados$textEmbedding)
word_index = tokenizer$word_index
vocab_size <- length(word_index)
vocab_size <- vocab_size + 1
vocab_size
cat("Found", length(word_index), "unique tokens.\n")
data <- pad_sequences(sequences, maxlen = maxlen)
trainIndex <- createDataPartition(dados$resposta, p=0.90, list=FALSE)
dados_train <- dados[ trainIndex,]
dados_test <- dados[-trainIndex,]
dados_train_sequence <- data[ trainIndex,]
dados_test_sequence <- data[-trainIndex,]
max_words <- vocab_size
word_index <- tokenizer$word_index
# Data Preparation --------------------------------------------------------
# Parameters --------------------------------------------------------------
embedding_dims <- 100
filters <- 132
main_input <- layer_input(shape = c(maxlen), dtype = "int32")
main_output <- main_input %>%
layer_embedding(vocab_size, embedding_dims, input_length = maxlen, name = "embedding") %>%
bidirectional(
layer_lstm(units = 128, return_sequences = TRUE)
) %>%
bidirectional(
layer_lstm(units = 64, return_sequences = TRUE, recurrent_dropout = 0.2)
) %>%
bidirectional(
layer_lstm(units = 32)
) %>%
layer_dense(units = 1, activation = 'sigmoid')
model <- keras_model(
inputs = c(main_input),
outputs = main_output
)
model %>% compile(
loss = "binary_crossentropy",
optimizer = "adam",
metrics = "accuracy"
)
library(keras)
# Training ----------------------------------------------------------------
history <- model %>%
fit(
x = list(dados_train_sequence),
y = array(dados_train$resposta),
batch_size = 32,
epochs = 5,
#callbacks = callbacks_list,
validation_split = 0.1
)
predictions <- model %>% predict(list(dados_test_sequence))
predictions2 <- round(predictions, 0)
matriz <- confusionMatrix(data = as.factor(predictions2), as.factor(dados_test$resposta), positive="1")
resultados <- addRowAdpater(resultados, "DESC", matriz)
View(resultados)
}
View(resultados)
resultados
library(ggplot2)
df1 <- data.frame(supp=rep(c("Baseline", "Proposed Framework"), each=3),
metric=rep(c("Recall", "Precision", "F1-Measure"),2),
len=c(76.722, 88.785, 82.313, 97.662, 99.782, 98.71))
View(df1)
data <- read.csv(file="boxplot/nossosexpsv4.csv", header=TRUE, sep=",")
View(data)
# Reorder varieties (group) (mixing low and high embeddings for the calculations)
new_order <- with(data, reorder(algorithm , f1_measure, mean , na.rm=T))
library(ggplot2)
data <- read.csv(file="boxplot/resultadosexp2.csv", header=TRUE, sep=",")
View(data)
library(ggplot2)
data <- read.csv(file="boxplot/resultadosexp2.csv", header=TRUE, sep=";")
View(data)
library(ggplot2)
data <- read.csv(file="boxplot/resultadosexp2.csv", header=TRUE, sep=";")
View(data)
# grouped boxplot
ggplot(data, aes(x=dataset, y=note, fill=treatment)) +
geom_boxplot()
library(ggplot2)
data <- read.csv(file="boxplot/resultadosexp2.csv", header=TRUE, sep=",")
View(data)
library(ggplot2)
data <- read.csv(file="boxplot/resultadosexp2.csv", header=TRUE, sep=",")
View(data)
library(ggplot2)
data <- read.csv(file="boxplot/resultadosexp2.csv", header=TRUE, sep=";")
View(data)
# grouped boxplot
ggplot(data, aes(x=dataset, y=note, fill=treatment)) +
geom_boxplot()
data
library(ggplot2)
data <- read.csv(file="boxplot/resultadosexp2.csv", header=TRUE, sep=";")
View(data)
library(ggplot2)
data <- read.csv(file="boxplot/resultadosexp2.csv", header=TRUE, sep=";")
data
data$ï..dataset
library(ggplot2)
data <- read.csv(file="boxplot/resultadosexp2.csv", header=TRUE, sep=";")
View(data)
library(ggplot2)
data <- read.csv(file="boxplot/resultadosexp2v3.csv", header=TRUE, sep=";")
library(ggplot2)
data <- read.csv(file="boxplot/resultadoexp2v3.csv", header=TRUE, sep=";")
View(data)
library(ggplot2)
data <- read.csv(file="boxplot/resultadoexp2v3.csv", header=TRUE, sep=";")
View(data)
library(ggplot2)
data <- read.csv(file="boxplot/resultadoexp2v3.csv", header=TRUE, sep=";")
View(data)
# grouped boxplot
ggplot(data, aes(x=dataset, y=note, fill=treatment)) +
geom_boxplot()
# grouped boxplot
ggplot(data, aes(x=dataset, y=f1_measure, fill=treatment)) +
geom_boxplot()
# grouped boxplot
ggplot(data, aes(x=dataset, y=f1_measure, fill=algorithm)) +
geom_boxplot()
ggplot(data, aes(fill=algorithm, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity")
ggplot(data, aes(fill=algorithm, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() +   geom_boxplot() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +scale_fill_brewer(palette="OrRd")
ggplot(data, aes(fill=algorithm, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +scale_fill_brewer(palette="OrRd")
library(ggplot2)
data <- read.csv(file="boxplot/resultadoexp2v3.csv", header=TRUE, sep=";")
data$algorithm <- as.factor(data$algorithm)
ggplot(data, aes(fill=algorithm, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +scale_fill_brewer(palette="OrRd")
library(ggplot2)
data <- read.csv(file="boxplot/resultadoexp2v3.csv", header=TRUE, sep=";")
#data$algorithm <- as.factor(data$algorithm)
data$algorithm <-factor(data$algorithm,levels=levels(data$algorithm)[c(3,1,2)])
ggplot(data, aes(fill=algorithm, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +scale_fill_brewer(palette="OrRd")
library(ggplot2)
data <- read.csv(file="boxplot/resultadoexp2v3.csv", header=TRUE, sep=";")
#data$algorithm <- as.factor(data$algorithm)
data$algorithm <-factor(data$algorithm,levels=levels(data$algorithm)[c(1,2,3,4,5,6)])
ggplot(data, aes(fill=algorithm, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +scale_fill_brewer(palette="OrRd")
library(ggplot2)
data <- read.csv(file="boxplot/resultadoexp2v3.csv", header=TRUE, sep=";")
#data$algorithm <- as.factor(data$algorithm)
data$algorithm <-factor(data$algorithm,levels=levels(data$algorithm)[c(1,2,3,4,5,6,7)])
ggplot(data, aes(fill=algorithm, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +scale_fill_brewer(palette="OrRd")
library(ggplot2)
data <- read.csv(file="boxplot/resultadoexp2v3.csv", header=TRUE, sep=";")
#data$algorithm <- as.factor(data$algorithm)
data$algorithm <-factor(data$algorithm,levels=levels(data$algorithm)[c(7,2,3,4,5,6,1)])
ggplot(data, aes(fill=algorithm, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +scale_fill_brewer(palette="OrRd")
library(ggplot2)
data <- read.csv(file="boxplot/resultadoexp2v3.csv", header=TRUE, sep=";")
#data$algorithm <- as.factor(data$algorithm)
data$algorithm <-factor(data$algorithm,levels=levels(data$algorithm)[c(1,2,3,4,5,6,7)])
ggplot(data, aes(fill=algorithm, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +scale_fill_brewer(palette="OrRd")
#data$algorithm <- as.factor(data$algorithm)
data$algorithm <-factor(data$algorithm,levels=levels(data$algorithm)[c(4,2,3,1,5,6,7)])
ggplot(data, aes(fill=algorithm, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +scale_fill_brewer(palette="OrRd")
#data$algorithm <- as.factor(data$algorithm)
data$algorithm <-factor(data$algorithm,levels=levels(data$algorithm)[c(1,2,3,4,5,6,7)])
ggplot(data, aes(fill=algorithm, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +scale_fill_brewer(palette="OrRd")
library(ggplot2)
data <- read.csv(file="boxplot/resultadoexp2v3.csv", header=TRUE, sep=";")
#data$algorithm <- as.factor(data$algorithm)
data$algorithm <-factor(data$algorithm,levels=levels(data$algorithm)[c(1,2,3,4,5,6,7)])
ggplot(data, aes(fill=algorithm, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +scale_fill_brewer(palette="OrRd")
library(ggplot2)
data <- read.csv(file="boxplot/resultadoexp2v3.csv", header=TRUE, sep=";")
#data$algorithm <- as.factor(data$algorithm)
data$algorithm <-factor(data$algorithm,levels=levels(data$algorithm)[c(1,2,3,4,5,6,7)])
ggplot(data, aes(fill=algorithm, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +scale_fill_brewer(palette="OrRd")
library(ggplot2)
data <- read.csv(file="boxplot/resultadoexp2v3.csv", header=TRUE, sep=";")
#data$classifier <- as.factor(data$classifier)
data$classifier <-factor(data$classifier,levels=levels(data$classifier)[c(1,2,3,4,5,6,7)])
ggplot(data, aes(fill=classifier, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +scale_fill_brewer(palette="OrRd")
library(ggplot2)
data <- read.csv(file="boxplot/resultadoexp2v3.csv", header=TRUE, sep=";")
#data$classifier <- as.factor(data$classifier)
#data$classifier <-factor(data$classifier,levels=levels(data$classifier)[c(1,2,3,4,5,6,7)])
data$classifier <-factor(data$classifier,levels=levels(data$classifier)[c(2,3,1,4,5,6,7)])
ggplot(data, aes(fill=classifier, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +scale_fill_brewer(palette="OrRd")
library(ggplot2)
data <- read.csv(file="boxplot/resultadoexp2v3.csv", header=TRUE, sep=";")
#data$classifier <- as.factor(data$classifier)
#data$classifier <-factor(data$classifier,levels=levels(data$classifier)[c(1,2,3,4,5,6,7)])
data$classifier <-factor(data$classifier,levels=levels(data$classifier)[c(2,3,1,4,7,5,6)])
ggplot(data, aes(fill=classifier, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +scale_fill_brewer(palette="OrRd")
ggplot(data, aes(fill=classifier, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))
+scale_fill_brewer(palette="OrRd")
ggplot(data, aes(fill=classifier, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +scale_fill_brewer(palette="OrRd")
gg <- ggplot(data, aes(fill=classifier, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) + scale_fill_brewer(palette="OrRd")
gg + scale_color_grey(start = 0.8, end = 0.2)
gg + scale_color_grey(start = 0.8, end = 0.2)
gg <- ggplot(data, aes(fill=classifier, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) + scale_fill_brewer(palette="OrRd")
gg + scale_color_grey(start = 0.8, end = 0.2)
ggplot(data, aes(fill=classifier, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) + scale_color_grey(start = 0.8, end = 0.2)
ggplot(data, aes(fill=classifier, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) + scale_color_grey(start = 0.8, end = 0.2)
ggplot(data, aes(fill=classifier, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) + scale_fill_grey(start = 0.8, end = 0.2)
ggplot(data, aes(fill=classifier, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) + scale_fill_grey(start = 0.5, end = 0.2)
ggplot(data, aes(fill=classifier, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) + scale_fill_grey(start = 1, end = 0.2)
ggplot(data, aes(fill=classifier, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) + scale_fill_grey(start = 0.8, end = 0.2)
ggplot(data, aes(fill=classifier, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) + scale_fill_grey(start = 0.8, end = 0.2)
ggplot(data, aes(fill=classifier, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) + scale_fill_grey(start = 0.8, end = 0.7)
ggplot(data, aes(fill=classifier, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) + scale_fill_grey(start = 0.8, end = 0.1)
ggplot(data, aes(fill=classifier, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) + scale_fill_brewer(palette="OrRd")
ggplot(data, aes(fill=classifier, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) + scale_fill_grey(start = 0.8, end = 0.1)
ggplot(data, aes(fill=classifier, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) + scale_fill_brewer(palette="OrRd")
ggplot(data, aes(fill=classifier, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) + scale_fill_grey(start = 0.8, end = 0.1)
ggplot(data, aes(fill=classifier, y=f1_measure, x=dataset)) +
geom_bar(position="dodge", stat="identity") + theme_classic() + theme(panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) + scale_fill_brewer(palette="OrRd")
